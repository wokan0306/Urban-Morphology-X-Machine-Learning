# -*- coding: utf-8 -*-
"""end-to-end-object-detection-with-transformers-detr.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZnnxYg_aRDb10sBS5nw3pTGVb5AtzaNy
"""

import os
import numpy as np 
import pandas as pd 
from datetime import datetime
import time
import random
from tqdm.autonotebook import tqdm


#Torch
import torch
import torch.nn as nn
from torch.utils.data import Dataset,DataLoader
from torch.utils.data.sampler import SequentialSampler, RandomSampler

#sklearn
from sklearn.model_selection import StratifiedKFold

#CV
import cv2

################# DETR FUCNTIONS FOR LOSS######################## 
import sys
sys.path.append('./detr/')

from detr.models.matcher import HungarianMatcher
from detr.models.detr import SetCriterion

from detr.models.detr import CustomDETR
#################################################################

#Albumenatations
import albumentations as A
import matplotlib.pyplot as plt
from albumentations.pytorch.transforms import ToTensorV2

#Glob
from glob import glob

"""# Utils

* AverageMeter - class for averaging loss,metric,etc over epochs
"""

class AverageMeter(object):
    """Computes and stores the average and current value"""
    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

"""# Configuration

Basic configuration for this model
"""

n_folds = 5
seed = 42
num_classes = 2
num_queries = 100
null_class_coef = 0.5
BATCH_SIZE = 32
LR = 2e-5 * 0.2
EPOCHS = 100

"""# Seed Everything

Seeding everything for reproducible results
"""

def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

seed_everything(seed)

"""# Preparing the Data

* For preparation of data I use code from Alex's awesome kernel [here](https://www.kaggle.com/shonenkov/training-efficientdet)
* The data can be split into any number of folds as you want , split is stratified based on number of boxes and source

# Augmentations

* As suggested by aleksendra in her kernel ,augentations will play a major role and hence took her up advice and use awesome augmentations , cut-mix and other will be included in future versions
"""

def get_train_transforms():
    return A.Compose([A.OneOf([A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, val_shift_limit=0.2, p=0.9),
                               
                      A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.9)],p=0.9),
                      
                      A.ToGray(p=0.01),
                      
                      A.HorizontalFlip(p=0.5),
                      
                      A.VerticalFlip(p=0.5),
                      
                      A.Resize(height=512, width=512, p=1),
                      
                      A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.5),
                      
                      ToTensorV2(p=1.0)],
                      
                      p=1.0,
                     
                      bbox_params=A.BboxParams(format='coco',min_area=0, min_visibility=0,label_fields=['labels'])
                      )

def get_valid_transforms():
    return A.Compose([A.Resize(height=512, width=512, p=1.0),
                      ToTensorV2(p=1.0)], 
                      p=1.0, 
                      bbox_params=A.BboxParams(format='coco',min_area=0, min_visibility=0,label_fields=['labels'])
                      )

"""# Creating Dataset

* I hope you have the video by now , DETR accepts data in coco format which is (x,y,w,h)(for those who do not know there are two formats coco and pascal(smin,ymin,xmax,ymax) which are widely used) . So now we need to prepare data in that format
"""

from pycocotools.coco import COCO
from PIL import Image
import torchvision.transforms as T
import numpy as np

class COCODataset(Dataset):
    def __init__(self, root_dir, coco_annotation, transform=None):
        ...
        self.coco = COCO(coco_annotation)
        self.image_ids = self.coco.getImgIds()
        self.transform = transform
        self.root_dir = root_dir
        
    def __getitem__(self, idx, max_no_objs=100):
        image_id = self.image_ids[idx]
        file_id = self.coco.loadImgs(image_id)[0]['file_name']  # Get file ID from image metadata
        image = np.array(Image.open(os.path.join(self.root_dir, file_id)).convert('RGB')).astype(np.float32)
        image /= 255.0
        ann_ids = self.coco.getAnnIds(imgIds=image_id)
        anns = self.coco.loadAnns(ann_ids)

        # Initialize an empty array to store the boxes
        boxes = np.empty((0, 4))
        z_values = []  # Initialize an empty list to store the z values

        for ann in anns:
            box = list(ann['bbox'])
            if box[2] > 0.00001 and box[3] > 0.00001:
                # Append the box to the 2D array
                boxes = np.vstack((boxes, box))
                z_values.append(ann['z'])  # Append the z value for this annotation

        area = boxes[:, 2] * boxes[:, 3]
        labels = np.zeros(len(boxes))
        z = np.array(z_values)  # Convert the z_values list to a NumPy array
        z[z > 80] = 80
        z = z / 80
        z = np.power(z, 0.5)
        if self.transform is not None:
            sample = {
                'image': image,
                'bboxes': boxes,
                'labels': labels,
            }
            sample = self.transform(**sample)
            image = sample['image']
            boxes = sample['bboxes']
            labels = sample['labels']

        target = {}
        _, h, w = image.shape
        target['boxes'] = torch.as_tensor(boxes, dtype=torch.float32) / h
        target['labels'] = torch.as_tensor(labels, dtype=torch.long)
        target['image_id'] = torch.tensor([image_id])
        target['area'] = torch.as_tensor(area, dtype=torch.float32)
        target['building_index'] = torch.as_tensor(z, dtype=torch.float32)

        return torch.as_tensor(image, dtype=torch.float32), target, image_id
        
    def __len__(self):
        return len(self.image_ids)

"""# Model

* Initial DETR model is trained on coco dataset , which has 91 classes + 1 background class , hence we need to modify it to take our own number of classes
* Also DETR model takes in 100 queries ie ,it outputs total of 100 bboxes for every image , we can very well change that too
"""

class DETRModel(nn.Module):
    def __init__(self,num_classes,num_queries):
        super(DETRModel,self).__init__()
        self.num_classes = num_classes
        self.num_queries = num_queries
        
        # Load the pretrained DETR model
        pretrained_model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)
        
        # Create a new CustomDETR model
        self.model = CustomDETR(pretrained_model.backbone, pretrained_model.transformer, num_classes=self.num_classes, num_queries=self.num_queries)
        
        # Load pretrained model parameters
        self._load_pretrained_parameters(pretrained_model)
        
        self.in_features = self.model.class_embed.in_features
        
        self.model.class_embed = nn.Linear(in_features=self.in_features,out_features=self.num_classes)
        self.model.num_queries = self.num_queries
        
    def forward(self,images):
        return self.model(images)
        
    def _load_pretrained_parameters(self, pretrained_model):
        pretrained_state_dict = pretrained_model.state_dict()
        custom_state_dict = self.model.state_dict()
        
        # Filter out unnecessary keys from pretrained_state_dict
        pretrained_state_dict = {k: v for k, v in pretrained_state_dict.items() if k in custom_state_dict and custom_state_dict[k].shape == v.shape}
        
        # Update custom_state_dict with the pretrained parameters
        custom_state_dict.update(pretrained_state_dict)
        
        # Load the new state_dict into the CustomDETR model
        self.model.load_state_dict(custom_state_dict)

"""# Matcher and Bipartite Matching Loss

Now we make use of the unique loss that the model uses and for that we need to define the matcher. DETR calcuates three individual losses :
* Classification Loss for labels(its weight can be set by loss_ce)
* Bbox Loss (its weight can be set by loss_bbox)
* Loss for Background class
"""

'''
code taken from github repo detr , 'code present in engine.py'
'''

matcher = HungarianMatcher()

weight_dict = {'loss_ce': 1, 'loss_bbox': 1 , 'loss_giou': 1, 'loss_building_index': 1}

losses = ['labels', 'boxes', 'cardinality', 'building_index']

"""# Training Function

Training of DETR is unique and different from FasteRRcnn  and EfficientDET , as we train the criterion as well , the training function can be viewed here : https://github.com/facebookresearch/detr/blob/master/engine.py
"""

def train_fn(data_loader,model,criterion,optimizer,device,scheduler,epoch):
    model.train()
    criterion.train()
    
    summary_loss = AverageMeter()
    
    tk0 = tqdm(data_loader, total=len(data_loader))
    
    for step, (images, targets, image_ids) in enumerate(tk0):
        
        images = list(image.to(device) for image in images)
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
        

        output = model(images)
        
        loss_dict = criterion(output, targets)
        weight_dict = criterion.weight_dict
        
        losses = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)
        
        optimizer.zero_grad()

        losses.backward()
        optimizer.step()
        if scheduler is not None:
            scheduler.step()
        
        summary_loss.update(losses.item(),BATCH_SIZE)
        tk0.set_postfix(loss=summary_loss.avg)
        
    return summary_loss

"""# Eval Function"""

def eval_fn(data_loader, model,criterion, device):
    model.eval()
    criterion.eval()
    summary_loss = AverageMeter()
    
    with torch.no_grad():
        
        tk0 = tqdm(data_loader, total=len(data_loader))
        for step, (images, targets, image_ids) in enumerate(tk0):
            
            images = list(image.to(device) for image in images)
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

            output = model(images)
        
            loss_dict = criterion(output, targets)
            weight_dict = criterion.weight_dict
        
            losses = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)
            
            summary_loss.update(losses.item(),BATCH_SIZE)
            tk0.set_postfix(loss=summary_loss.avg)
    
    return summary_loss

"""# Engine"""

def collate_fn(batch):
    return tuple(zip(*batch))

import sys
import os
log_file = open('log.txt', 'w')
sys.stdout = log_file

train_dataset = COCODataset(root_dir="images", coco_annotation="train_coco.json", transform=get_train_transforms())
train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, collate_fn=collate_fn)

val_dataset = COCODataset(root_dir="images", coco_annotation="valid_coco.json", transform=get_valid_transforms()) 
valid_data_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, collate_fn=collate_fn)

device = torch.device('cuda')
model = DETRModel(num_classes=num_classes,num_queries=num_queries)
model = model.to(device)
criterion = SetCriterion(num_classes-1, matcher, weight_dict, eos_coef = null_class_coef, losses=losses)
criterion = criterion.to(device)


optimizer = torch.optim.AdamW(model.parameters(), lr=LR)

best_loss = 10**5
for epoch in range(EPOCHS):
    train_loss = train_fn(train_data_loader, model,criterion, optimizer,device,scheduler=None,epoch=epoch)
    valid_loss = eval_fn(valid_data_loader, model,criterion, device)
    
    print('|EPOCH {}| TRAIN_LOSS {}| VALID_LOSS {}|'.format(epoch+1,train_loss.avg,valid_loss.avg))
    
    if valid_loss.avg < best_loss:
        best_loss = valid_loss.avg
        print('Best model found in Epoch {}........Saving Model'.format(epoch+1))
        torch.save(model.state_dict(), f'detr_best-3D.pth')

log_file.close()